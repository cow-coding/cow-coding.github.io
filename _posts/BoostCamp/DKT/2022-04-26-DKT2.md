---
layout: post
date: 2022-04-26 02:30:00 PM
title: "[BoostCamp AI Tech / RecSys] Day67 - Sequence Modelling"
categories: [NAVER BoostCamp AI Tech, DKT]
tags: [Deep Learning, NAVER, BoostCamp, AI Tech, DKT]
math: true
---

# DKT : Sequence Modelling

---

## Sequence Modelling

- Sequence Modelling이란 단순한 tabular 데이터를 활용하는 것이 아닌 1개의 행이 어떤 유저나 요소의 시간적 데이터의 일부인 sequence data를 적용하는 모델
- sequence data를 tabular 형태로 전환해서 feature engineering과 같은 방식을 통해 학습하는 경우도 많음
- 하지만 이 과정에서 aggregation을 진행하다보니 누락되는 정보가 많이 발생함
- 이를 해결하고자 sequnce data를 그대로 사용하는 방식을 사용하는 sequence modelling을 사용
- 하지만 tabular에서도 데이터 누락을 최소화 하는 방식으로 진행할 수 있음
  
---

## Train/Valid Data split

- validation loss를 계산하기 위해 train-valid split을 진행해야 함
- 이 과정에서 **어떤 기준으로 분할**하는가가 중요함
- 학습과정에서 test data leakage가 발생한다면 test 성능이 좋게 나오지만 실제 서비스에서 좋지 않은 성능이 나올 수도 있음
- DKT의 경우 행을 기준으로 나누는 일반적인 split과 다르게 user별로 묶고 user를 기준으로 split을 진행해야함
  - DKT같은 정보는 **새로운 유저**에 좋은 효과를 보이는가?가 핵심 목적이기 때문

---

## Sequential Approach

### Sequential Model

- One-to-One : 종가예측과 같은 1개의 sequential을 통해 예측
- One-to-Many : 1개의 사진을 넣으면 사진에 걸맞는 설명을 보내주는 모델
- Many-to-One : DKT처럼 sequence data를 넣어주면 1/0과 같은 classification이나 종가 예측같은 일정 기간의 정보를 주면 regression 정답을 도출하는 모델
- Many-to-Many : 일반적인 NLP에서 자주 사용하는 모델
- Seq2Seq : n개의 입력으로 k개의 출력의 형태로 변환해주는 모델, 일반적으로 번역기에 많이 사용

### Sequential feeding

- sequential 모델에 데이터를 피딩하는 경우 여러가지 방식을 쓸 수 있음
- 기본적으로 **seqeunce length**에 데이터를 맞춰야 함
  - sequential data는 상황에 따라 그 길이가 다른 경우가 있는데, 이 경우 그 길이들을 잘 맞춰줘야 함
- 데이터를 feeding하는 경우 모든 데이터가 numeric이고 continuos면 단순히 LSTM에 `input_size`(feature 개수), `hidden_size`를 결정해주면 됨
- 만약 연속형과 범주형이 혼합된 데이터라면 **범주형 데이터는 embedding**을 해야함
  - LSTM에 들어가는 input은 continuous feature + embedding size의 형태로 처리하는 경우가 많음

### Embedding

- pytorch는 `nn.Embedding`을 사용하면 특정 값을 embedding size의 lookup table에 임베딩할 수 있음
- `nn.Embedding(category_range, embedding_dim)`을 사용하면 됨
- embedding layer로 학습을 통해 loss를 가장 최적화 시켜주는 방향으로 embedding 값을 조정함

