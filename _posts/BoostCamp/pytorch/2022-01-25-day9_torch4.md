---
layout: post
date: 2022-01-25 07:00:00 PM
title: "[BoostCamp AI Tech] Day9 - Datasets & Dataloaders"
categories: [NAVER BoostCamp AI Tech, PyTorch]
tags: [NAVER, BoostCamp, AI Tech, Python, Basic, PyTorch]
math: true
---
# PyTorch : Datasets & Dataloaders

---

## PyTorch Data 구조

### 1. Data
- 데이터는 데이터 그 자체를 의미한다.
- 정제되거나 전처리, 누적이 이미 다 되어 들어오는 경우도 많지만 아닌 경우도 있다.
- 보통 데이터 엔지니어 통해서 데이터가 정리가 되어 오는 경우가 많다.

### 2. Dataset
- Dataset class는 이미 구현되어 있는 것을 상속에서 세팅하는 경우가 많다.
- `__init__()`, `__len()__`, `__getitem()__`과 같이 필수적으로 생성해줘야하는 것들이 존재한다.
    - `__init__()` : 데이터를 로드하는 방법을 세팅하는 부분이다. 일반적으로 X, y를 지정하거나 다른 메서드들에 사용하는 attribute들을 세팅해주는 경우가 많다.
    - `__len()__` : 흔히 어떤 데이터셋을 `len(dataset)`으로 처리했을 때 어떤 값을 반환할 지를 구현하는 부분이다.
    - `__getitem()__` : 파라미터에 self와 함께 idx가 들어오는 경우가 일반적이다. 이 매직메서드는 우리가 일반적으로 `[]`으로 데이터에 접근할 때 어떻게 반환하는 가를 구현하는 부분이다. map-style이라고도 한다.

### transforms
- `transforms`는 전처리하는 부분을 다루고 있다.
- `dataloader`에 transform 파라미터가 존재하는데 이 부분에 들어갈 것들을 처리한다.
- `ToTensor()`, `CenterCrop()` 같은 것들이 들어간다.
- 보통 실제 구현하는 경우는 잘 없다...

### DataLoader
- 우리가 구현한 모델에 data feeding을 하는 부분이다.
- batch단위로 분리해주고 data shuffle, sampling 등을 진행해서 model에 데이터를 제공한다.

## Dataset Class
- 앞서 간단히 말했지만 데이터의 입력 형태를 결정하는 클래스이다.
- 데이터의 종류에 따라 입력을 다르게 정의해야한다.
    - 이미지, 텍스트, 오디오등 데이터의 형식이 가장 중요한 포인트이다.

```python
import torch
from torch.utils.data import Dataset

class MyDataset(Dataset):
    def __init__(self, data, labels):
        self.X = data
        self.y = labels
    
    def __len__(self):
        return len(self.y)
    
    def __getitem__(self, idx):
        label = self.y[idx]
        data = self.X[idx]

        return data, label
```  
- 이때 `__getitem__`의 형식도 자유자재로 데이터에 맞춰 결정해주면 좋다.
    - classification 문제는 dict type으로 반환하는 경우가 많다.
- 모든 것을 데이터 생성시점에 처리할 필요는 없다. 데이터를 한번에 불러오면 그 자체가 무거워질 수 있기 때문이다.
    - image data의 경우 Tensor변화는 학습에 필요한 시점에 변환한다.
- 팀원들과의 협업에서 데이터 셋의 표준 처리방법을 제공 및 공유하는 것이 좋다.

## DataLoade class

```python
DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, 
            num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, 
            worker_init_fn=None, multiprocessing_context=None, generator=None, *, 
            prefetch_factor=2, persistent_workers=False)
```

- DataLoader는 여러 데이터를 묶어서 model에 feed하는 역할을 한다.
- Data의 batch를 생성하는 역할을 한다.
- 학습직전 (GPU feed전) 데이터의 변환을 책임진다.
- 주로 tensor변환, batch 처리가 메인 업무이다.
- 주목할 파라미터
    - `sampler` : data 추출기법을 설정하는 부분이다.
    - `collate_fn` : variable length(가변길이)의 데이터를 batch 단위로 처리할 때 남은 데이터에 대해 padding을 설정해준다.  
        보통 sequence data에 많이 사용한다.

```python
data = ['apple', 'dog', 'cat', 'banana', 'tomato']
labels = [1, 0, 0, 1, 1]
MyData = MyDataset(data, labels)

MyDataLoader = DataLoader(MyData, batch_size=2, shuffle=True)
next(iter(MyDataLoader))
# [('apple', 'tomato'), tensor([1, 1])]

MyDataLoader = DataLoader(MyData, batch_size=2, shuffle=True)
for dataset in MyDataLoader:
    print(dataset)
'''
[('dog', 'apple'), tensor([0, 1])]
[('cat', 'banana'), tensor([0, 1])]
[('tomato',), tensor([1])]
'''
```
