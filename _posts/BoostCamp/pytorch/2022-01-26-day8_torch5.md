---
layout: post
date: 2022-01-26
title: "[BoostCamp AI Tech] Day8 - Monitoring tools for PyTorch"
categories: [NAVER BoostCamp AI Tech, PyTorch]
tags: [NAVER, BoostCamp, AI Tech, Python, Basic, PyTorch, tensorboard, WandB, monitoring]
math: true
---
# PyTorch : Monitoring tools for PyTorch

---

## Machine Learning Monitoring Tools

- 머신러닝 모델 학습의 모니터링 툴은 다양하게 존재한다.
- 대표적인 것이 [Tensorboard와](https://www.tensorflow.org/tensorboard?hl=ko) [weight & biases](https://wandb.ai/site)이다.

## Tensorboard

![](/image/boostcamp/pytorch/tensorboard.png){: w="450"}

- 원래는 TensorFlow의 프로젝트로 만들어진 시각화 도구이다.
- 학습 그래프, metric과 같은 다양한 수치들에 대해 시각화를 지원해준다.
- TensorFlow project의 일환이었으나 이제는 다양한 DL 프레임워크들이 연결해서 사용하고 있다.  
    물론 PyTorch도 마찬가지다.
- Tensorboard 값
    - scalar : metric 등 상수값의 epoch를 표시
    - graph : 모델의 computational graph vytl
    - histogram
    - Image

### Tensorboard in Colab

```python
from torch.utils.tensorboard import SummaryWriter
import numpy as np

PATH = "project"
exp = f"{PATH}/ex1"
writer = SummaryWriter(exp)
for n_iter in range(100):
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
writer.flush()
```

- Tensorboard 기본 세팅이다.
- 보통 로그를 기록하는 파일 양식은 `project이름/실험명`의 형식으로 저장한다.
- `SummaryWriter` 객체는 기록을 진행하는 객체이다. 이 객체에 scalar등 위에 언급한 값들을 입력할 수 있다.
- `writer.add_scalar()`는 scalar값을 기록하는 역할을 한다.
    파라미터에서 `n_iter`는 x축에 들어가는 값을 의미한다.
- 코랩에서 텐서보드를 실행하기 위해서는 매직커맨드를 활용해야한다.  
    참고로 safari에서는 잘 안된다. 크롬을 권장한다.  
    ```ipynb
    %load_ext tensorboard
    % tensorboard --logdir {logs_base_dir}
    ```  
    위의 코드를 실행하면 코랩 자체에서도 텐서보드 확인이 가능하고 포트상으로는 6006포트에 활성화된다.

## Weight and Biases

![](/image/boostcamp/pytorch/wandb.png){: w="450"}

<center>
<a href="https://wandb.ai">Weight and Biases</a>
</center>

- 머신러닝 실험에서 자주 활용되는 도구이다.
- 다른 사람들과 실험을 라이브로 공유하기에 최적화된 도구이다.
- MLOps의 대표적인 툴로 자주 사용되는 중이다.

### WandB in Colab

```python
!pip instal wandb -q
import wandb
wandb.init(project="my_project_name", entity="user_name")
```

- 위처럼 연결하면 wandb에 연결된다. 
- 솔직히 코랩연결보단 그냥 페이지에서 보는게 나은 것 같다.

```python
EPOCHS = 100
BATCH_SIZE = 64
LEARNING_RATE = 0.001

config={"epochs": EPOCHS, "batch_size": BATCH_SIZE, "learning_rate" : LEARNING_RATE}

wandb.init(project="my_project_name", config=config)
# wandb.config.batch_size = BATCH_SIZE
# wandb.config.learning_rate = LEARNING_RATE
# config={"epochs": EPOCHS, "batch_size": BATCH_SIZE, "learning_rate" : LEARNING_RATE}

for e in range(1, EPOCHS+1):
    '''
    your train valid code
    '''
        
    train_loss = epoch_loss/len(train_dataset)
    train_acc = epoch_acc/len(train_dataset)
    print(f'Epoch {e+0:03}: | Loss: {train_loss:.5f} | Acc: {train_acc:.3f}')
    wandb.log({'accuracy': train_acc, 'loss': train_loss})
```
- 자신의 훈련을 위한 모델의 parameter를 config로 설정해서 전달해준다.
- 해당 모델의 훈련값이 `wandb.log` 코드를 통해 wandb에 전달되어 라이브로 기록되는 것을 알 수 있다.

## PyTorch Lightning Logging

![](/image/boostcamp/pytorch/pl_log.png){: w="450"}

- PyTorch Lightning에도 모델 학습 기록을 하는 모듈이 존재한다.
- 물론 기록을 확인하는 것은 tensorboard를 쓰는 것으로 보인다.
- 앞서 [파이토치 라이트닝을 간단히 소개한 적](https://cow-coding.github.io/posts/day8_torch2/#pytorch-lightning)이 있는데, pytorch lightning은 `Trainer`객체를 활용해서 모델의 학습이 진행된다.  
그렇기 때문에 deafult 폴더가 아닌 다른 폴더에 기록을 전달하고 싶다면 `Trainer`에 `TensorBoardLogger`를 파라미터로 전달해 줄 필요가 있다.`TensorBoardLogger`말고 다른 로거들을 사용할 수도 있다.

```python
from pytorch_lightning import Trainer

# Automatically logs to a directory
# (by default ``lightning_logs/``)
trainer = Trainer()
# To see your logs
# tensorboard --logdir=lightning_logs/ 

# If you wand custom logger
from pytorch_lightning import loggers as pl_loggers

tb_logger = pl_loggers.TensorBoardLogger("logs/")
trainer = Trainer(logger=tb_logger)
```

### Automatic Logging
- `log()`를 사용하면 라이트니의 자동 로그 기능을 사용할 수 있다.
- `training_step`의 구현부에 추가로 log를 작성해주면 되는 것으로 보인다.
- `log`의 파라미터를 조정해서 매뉴얼로 조작이 가능하다.
    - `one_step` : 현재 단계의 metric을 기록 `training_step()`의 deafult는 True
    - `on_epoch` : epoch 종료시 자동으로 누적해서 기록
    - `prog_bar` : 훈련의 진행률을 표시해준다.
    - `logger` : `Trainer`에 전달한 사용자 정의 로거에 기록할지 여부를 결정한다.

```python
def training_step(self, batch, batch_idx):
    self.log("my_metric", x)

# or a dict
def training_step(self, batch, batch_idx):
    self.log("performance", {"acc": acc, "recall": recall})

# manual logger
def training_step(self, batch, batch_idx):
    self.log("my_loss", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)
```

- `log`를 이용해서 기록할 수도 있지만 직접 기록할 로그를 설정할 수 있다.

```python
def training_step(self):
    ...
    # the logger you used (in this case tensorboard)
    tensorboard = self.logger.experiment
    tensorboard.add_image()
    tensorboard.add_histogram(...)
    tensorboard.add_figure(...)
```

- 이 외에 자세한 사용법은 [공식문서](https://pytorch-lightning.readthedocs.io/en/stable/extensions/logging.html)를 통해 확인할 수 있다.