---
layout: post
date: 2022-02-18 07:50:00 AM
title: "[MLOps Specialization / Step3] AutoML"
categories: [Date Engineering, MLOps]
tags: [Data Engineering, MLOps, Coursera]
math: true
---

# AutoML

**이 포스트는 Coursera의 MLOps Specialization 강의 내용을 기반으로 작성되었습니다.**

---

## Intro to AutoML

- AutoML은 pipeline, model 생성, 학습을 모두 통합한 기술
- 모든 ML workflow를 자동화하는 것이 AutoML
- AutoML의 핵심 기술은 **Neural Architecture Search**  
  (NAS는 AutoML의 sub-field일뿐 전체가 아님)
  - Search Space
    - 신경망 구조의 범위를 정의 (search space)
    - 문제의 크기를 감소하거나
    - 인간 지식 너머의 것들 등...
  - Search Strategy
    - 선정된 search space를 어떻게 탐색할 것인가?
    - search space의 신경망 후보군을 선택
  - Performance Estimation Strategy
    - 선택된 후보군에 대해 지표를 측정하고 비교를 진행
    - 평가를 기반으로 다시 탐색 전략을 선정

---

## Understanding Search Spaces

![](/image/DataEngineering/MLOps/chapter3/search_space.png){: w="650"}

- Search Space에는 2가지 종류가 존재
  - Macro
  - Micro

![](/image/DataEngineering/MLOps/chapter3/macro.png){: w="650"}

- Macro
    - 한층씩 쌓으며 최적을 찾는 방법
    - Chain structed space : 레이어를 연속적으로 쌓는 것
    - Complex search space : 연속적으로 레이어를 연결하는 것이 아닌 가지로 뻗어나가거나 [skip connection](https://lswook.tistory.com/105) 원리를 활용

![](/image/DataEngineering/MLOps/chapter3/micro.png){: w="650"}

- Micro
  - cell(작은 neural net)을 쌓는 방식
  - Macro보다 좋은 성능을 냄
  - 1개의 레이어를 다른 cell로 대체하면 더 복잡한 구조를 표현할 수 있음

---

## Search Strategies

### Grid / Random Search

- Grid Search는 모든 가능성을 탐색
  - 매우 소모적인 탐색방식
- Random Search는 다음 옵션을 무작위로 선정
- 둘 다 **작은 search space**에 적합
- **search spcae 크기가 커지면 빠르게 실패**

### Bayesian Optimization

- 성능에 기반한 **특정한 확률분포를 추정**
- 테스트된 architecture들은 확률분포를 제한하고 이를 토대로 다음 옵션을 선정
- 이 방식은 유망한 architecture이 stochastic하게 결정됨  
  = 테스트 결과와 제한된 분포에 기반한 결과라는 의미

### Evolutionary Methods

![](/image/DataEngineering/MLOps/chapter3/evolutionary.png)

- 기본 원리는 유전 알고리즘

1. 랜덤한 초기의 n개의 architecture를 생성하고 estimation strategy로 성능 평가
2. X개의 높은 부모 architecture를 선정하여 새로운 N개의 **자식 구조 생성**
   - 이때 자식 architecture는 **부모를 복제하되 무작위로 일부를 대체하거나 변형**
     - 부모 구조의 변형은 특정 층이나 연결을 제거하거나
     - 레이어의 크기나 하이퍼파라미터를 변경하는 경우도 있음
   - 부모 구조를 조합하는 경우도 있음
3. 다시 estimation strategy에 기반해 성능 평가
4. 이 중 오래되거나 좋지 않은 성능을 보이는 N개의 architecture 제거(탈락)
5. 2에서 생성한 자식구조들은 4에서 제거된 N개의 부모 자리에 대체되어 과정을 반복

### Reinforcement Learning

![](/image/DataEngineering/MLOps/chapter3/rl.png)

- Agent는 보상을 최대화하는 방향으로 학습
- 가능한 옵션은 search space에서 선택하는 것들
- 성능평가 전략은 보상을 주는 방식으로 결정

---

## Measuring AutoML Efficacy

- 성능 평가 전략으로는 컴퓨팅적으로 부담스러운지, 시간 소모와 높은 GPU 사용량, 비용적으로 비싼가 등이 있음

### Lower Fidelity Estimates

- 문제를 재학습하는데 들이는 시간을 줄이는 것이 목표
- Data subset
  - 비용을 줄일 수 있음
  - 성능에서 저평가 발생가능
- Low resolution images
- Fewer filters and cells
  - 최근에는 이 방식 사용 안함

### Learning Curve Extrapolation

![](/image/DataEngineering/MLOps/chapter3/lce.png)

- learning curve가 믿을만하게 예측하기 위한 매커니즘
- initail learning에 기반하여 추론을 진행
- 낮은 성능을 보이는 것들은 탈락

### Wight Inheritance/Network Morphisms

- 이전에 학습한 architecture에 기반하여 새 architure의 가중치를 초기화
  - 간단한 방식의 전이학습
- **Network Morphism**을 활용
  - Network morphism : 수정을 하되 내부의 함수는 변경하지 않음
  - Underlying function을 변경하지 않으므로 **새로운 네트워크는 부모 네트워크의 지식을 상속받**고 계산 성능이 향상

