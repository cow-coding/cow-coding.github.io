---
layout: post
date: 2022-02-19 07:52:00 AM
title: "[MLOps Specialization / Step4] Introduction to Model Serving"
categories: [Data Engineering, MLOps]
tags: [Data Engineering, MLOps, Coursera]
math: true
---

# Introduction to Model Serving

**이 포스트는 Coursera의 MLOps Specialization 강의 내용을 기반으로 작성되었습니다.**

---

## Introduction to Model Serving

![](/image/DataEngineering/MLOps/chapter4/intro1.png)

- 모델 서빙 패턴
  - 모델
  - interpreter and execution
  - 입력 데이터
- 위 3가지 과정은 추론에 활용
- ML workflows
  - 모델 학습
  - 모델 예측
- 위 과정은 batch inference나 tlftlrks inference에 활용
- 주요한 지표
  - Latency
  - Throughput
  - Cost

### Latency

- **user의 행동과 그에 따른 어플리케이션의 반응까지의 딜레이**
- Latency는 전체 프로세스, 데이터에서 서버로의 전송시기, 추론 과정 등 모든 과정에서 발생 가능
- 적은 latency는 고객 만족도 유지의 핵심 필수요건

### Throughput

- **1초에 성공적인 수행이 가능한 요청**
- 일부 어플리케이션은 지연율보다 처리율만 중요한 경우도 있음

### Cost

- **각 inference와 관련된 cost는 최소화되어야 함**
- 중요한 Infrastructure 요규사항은 비용이 비쌈
  - CPU
  - GPU같은 가속 HW
  - Caching infra

결과적으로 위의 3가지 요소가 조화를 이루는 것이 가장 좋습니다. **지연율은 줄이고 처리율은 높이는 것**의 방향과 **비용, 지연율, 처리율이 균형**을 이루는 것 등 여러 관점으로 바라봐야 합니다.
