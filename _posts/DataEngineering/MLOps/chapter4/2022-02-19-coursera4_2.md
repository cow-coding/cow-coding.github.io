---
layout: post
date: 2022-02-19 07:53:00 AM
title: "[MLOps Specialization / Step4] Introduction to Model Serving Infrastructure"
categories: [Data Engineering, MLOps]
tags: [Data Engineering, MLOps, Coursera]
math: true
---

# Introduction to Model Serving Infrastructure

**이 포스트는 Coursera의 MLOps Specialization 강의 내용을 기반으로 작성되었습니다.**

---

## Introduction to Model Serving Infrastructure

- 모델의 복잡도가 증가하면 같이 증가하는 것들
  - 모델 크기
  - Complex functons
  - 예측 지연율
  - 예측 정확도
  - 비용 (HW / SW 모두)
- 비용과 모델의 복잡도가 균형을 이뤄야 함 (단순히 연구가 아닌 배포가 목적이므로)
  - 예측 효율과 지연율 속도간에는 trade off가 발생

### Maintaining Input Feature Lookup

- 모든 feature가 예측에 활용되는 것은 아님
  - 예를 들어 음식 배달관련으로는 주문이 들어온 시간과 과거에 분당 취소된 주문 수 정도만 필요
- 추가적은 **pre-computed or aggregated feature**들은 실시간으로 데이터 저장소로 부터 읽혀야 함
- 이 과정에서 비용이 발생

---

## Deployment Options

![](/image/DataEngineering/MLOps/chapter4/dep.png)

- Huge data centers
    - **Model 효율과 비용이 모두 중요**
    - 리소스 활용 최적화
    - 비용의 최소화
- Embedded devices
  - 모바일 핸드폰에 들어가는 경우 고려해야할 것들이 꽤 있음
  - 평균적인 GPU 메모리는 4기가미만
  - 평균 앱 크기는 11메가
  - 사용자는 너무 많은 device resource 소모를 좋아하지 않음  
    $\rightarrow$ 설치하지 않는 결과로 연결
- Edge device의 제한된 환경에 대한 해결책으로 **REST API**를 활용한 서버와의 통신을 통한 예측을 활용
  - 모델 자체는 서버에 두고 API 통신으로 예측을 수행

---

## Improving Prediction Latency and Reducing Resource Costs

- Profile and Benchmark
  - 적합한 후보 모델을 선택하거나 구축한 후 모델을 profiling하고 벤치마킹
- Optimize Operators
  - TF Lite 등을 활용해 통계 지표를 확인 가능
  - 이를 활용해 성능 병목 현상 확인
  - 연산 시간에 지배적인 operator 식별 가능
- Optimize Model
  - 모바일 기기에서 중요
- Tweak Threads
  - thread 수를 늘려 앱 실행속도 증가
  - 하지만 energy 사용량이 증가하므로 효율성을 고려해야함