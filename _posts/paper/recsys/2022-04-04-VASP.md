---
layout: post
date: 2022-04-04 01:00:00 PM
title: "[Paper Review] Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP)"
categories: [Paper Review, Recommender System]
tags: [NAVER, BoostCamp, AI Tech, VAE, VASP, EASE, paper review, recommender system]
math: true
---

# Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP) (2021)

---

## 논문 소개

![](/image/paper/vasp/vasp1.png)*출처 : Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP)*

<center>
<a href="https://arxiv.org/abs/2102.05774"><bold>Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP)</bold></a>
</center><br>

VASP는 2021년 2월에 나온 따끈따끈한 논문입니다. 추천 시스템에서 Benchmark 상위를 차지하고 있는 모델이며 추천 시스템에서 크게 효과를 보인 EASE와 VAE를 활용한 모델입니다. 실제 논문 상에서 엄청 특별한 수식적 접근이나 뛰어난 연구적 접근이 있지는 않다고 생각하지만 2개의 모델을 앙상블해서 좋은 효과를 보였다고 생각됩니다.

---

## Abstract

- EASE 알고리즘은 Top-N 추천 task에서 좋은 성능을 보였고 VAE는 최근 추천 시스템에서 관심도가 높음
- 이 논문에서는 EASE를 현대의 신경망 기술로 학습하여 성능을 향상시킨 **Neural EASE**를 
- identity(여기서는 Input으로 보임)에 과적합되지 않으면서 다중 비선형 레이어의 이점을 보여주는 deep autoencoder인 **FLAVE**를 제시함
- FLAVE와 Neural EASE를 병렬적으로 학습하는 방식을 활용

---

## Introduction

- RS에서는 수백만의 유저와 아이템을 다루는 큰 규모의 데이터를 다루는 기술
- 이런 상황에서 content는 dynamic하게 변화하고 실시간으로 처리되는 데이터에 대해 충분히 **빠르게 학습**해야하고 **높은 재현률**을 보여줄 필요가 있음
- EASE는 단순한 선형모델임에도 identity에 과적합하는 문제를 잘 해결하고 explainable한 결과를 제공함
- 이를 활용해서 **복잡한 비선형 패턴을 처리하는 deep autoencoder**의 잠재력을 활용하며 **EASE처럼 설명가능한** 모델을 구축할 것
- 전통적인 dropout을 통한 과적합 방지는 매우 deep한 구조에서는 효과가 좋지 않음
- 
### 문제제기

- The overfitting towards identity
  - identity에 overfitting되는 문제 발생 $\rightarrow$ EASE에서 해결
- deep architecture에서는 dropout이 overfitting 해결에 큰 도움이 되지 않음
  - 새로운 방식의 data augmentation을 진행해야함
- 추천 시스템의 근원적인 문제인 niche item의 interaction이 부족한 것을 해결할 필요가 있음

### 문제 해결 방향

- Top-N 추천 : focal loss를 활용한 long-tail 문제 방지
- 과적합 방지 : 간단한 data augmentation 기술 활용
- 앙상블 : 아다마르 곱(**element-wise**)을 활용한 여러모델 학습
- **VASP는 deep VAE와 Neural EASE를 결합하여 함께 학습함**
  - 이 과정에서 선형적 특징과 비선형적 특징을 모두 모델링함


---

## Related Work

- 다양한 관련된 연구들에 대해 장단점을 나열하고 있음
- 핵심적인 모델들 위주로 정리

### AutoRec

- 2016년에 나온 AutoRec은 autoencoder 기반의 CF 모델을 활용하여 좋은 성능을 보였음
- 이 모델에서는 **explicit rating**을 활용했음

### Multi-VAE

- 2018년에 나온 Variational AutoEncoder (VAE)를 활용한 CF 모델. 
- Multi-VAE라고도 함
- **Multinomial log-likelihood 데이터 분포**를 활용한 모델

### EASE

- *Embarassingly Shallow Autoencoder for Sparse Data*에서 공개한 모델
- deep architecture에 반대되는 hidden layer가 없는 Autoencoder 모델
- SOTA 모델을 달성한 모델로 유명함

### Wide & Deep

- 단순하고 shallow하거나 복잡한 architecture를 갖는 다양한 모델들이 나타남
- Wide & Deep이라 불리는 위의 2가지 특징을 조합한 모델이 등장
- 두 특징을 조합하는 과정에서 **joint training**이라 불리는 기술을 사용함
- Wide & Deep에서 사용한 아이디어를 활용해서 **item attribute가 아닌 interaction을 사용**해서 비선형 패턴을 찾는 방식을 설계함

### Other fields

- CV나 NLP에서 사용하는 딥러닝 기술이 추천 시스템에 적용되어 좋은 성능을 보임
- 대표적인 예는 Residual Network와 RecVAE가 있음
- 이런 점에서 **Focal Loss (FL)** 를 추천 시스템에 적용함
  - Focal Loss는 object detection에서 나타나는 불균형한 class에 적용하는 loss function
  - **Class imbalance는 추천 시스템의 niche item interaction**과 동일하게 생각할 수 있음
  - 이런 점에서 CF에서 나타는 cold start problem을 해결할 수 있을 것임

---

## Model Architecture

![](/image/paper/vasp/vasp4.png){: w="550"}

- 논문에서 VASP의 구조는 크게 세부분으로 나눠짐
- EASE 모델을 사용하는 **Neural EASE**
- Variational AutoEncoder를 사용하는 **FLVAE**
- 두 모델의 결과를 **Hadamard product를 활용해서 합치는** VASP 부분

### 기본 notation

$$
\begin{aligned}
& u \in \{ 1, ... , U \} : \text{user} \\
& i \in \{ 1, ... , I \} : \text{item} \\
& \mathbf{x}_u = [ x_{u1}, x_{u2}, ..., x_{uI} ]^\intercal \in \mathbb{N}^I : \text{user u interaction history} \\
& \hat{\mathbf{x}}_u = [ x_{u1}, x_{u2}, ..., x_{uI} ]^\intercal \in \mathbb{N}^I : \text{user u predicted ratings}
\end{aligned}
$$

### Neural EASE

![](/image/paper/vasp/vasp5.png)

- EASE 논문에 따르면 EASE의 수식은 다음과 같음

$$
\hat{\mathbf{x}_u} = W \cdot \mathbf{x}_u, \quad W \in \mathbf{R}^{|I| \times |I|}
$$

- identity overfitting 방지를 위해 가중치 행렬인 **$W$의 대각성분은 모두 0으로 제한함**
- EASE 논문에 따르면 $\mathbf{x}_u$와 $\mathbf{x}_u$의 square loss는 closed-form을 띄므로 목적함수로 사용할 수 있음
- FLVAE와 함께 학습을 하고 backpropagation을 진행해야 하므로 **single layer perceptron**으로 EASE를 구현함
- layer의 대각 weight 성분은 반드시 0으로 제한하며 bias node는 없음

![](/image/paper/vasp/vasp6.png)*Neural EASE의 loss function 성능표*

- 논문에 따르면 **cosine proximity**를 사용하는 것이 Neural EASE loss function에서 가장 좋은 것으로 확인됨
- PyTorch로 구현하는 경우 `torch.nn.functional.cosine_similarity`를 사용하면 됨

### MultiVAE with focal loss (FLVAE)

![](/image/paper/vasp/vasp7.png){: w="500"}

$$
\begin{matrix}
\mathbf{z}_u \sim N(0, \mathbf{I}_k) \\
\pi(\mathbf{z}_u) \varpropto exp\{f_{\theta}(\mathbf{z}_u)\} \\
\mathbf{x}_u \sim Mult(N_u, \pi(\mathbf{z}_u))
\end{matrix}
$$

- latent representation $\mathbf{z}_u$는 평균이 0, 표준편차가 $\mathbf{I}_k$인 가우시안 분포에서 추출
- 신경망 $f_{\theta}(\cdot)$은 아이템 $I$에 대한 확률분포 $\pi(\mathbf{z}_u)$를 유도함
- interaction history $\mathbf{x}_u$는 유도된 $\pi(\mathbf{z}_u)$를 활용한 다항분포에서 유도

$$
\log p \geq \mathbb{E}_q[ \log p(\mathbf{x}_u\mid\mathbf{z}_u) - KL(q(\mathbf{z}_u|\mathbf{x}_u) \Vert p(\mathbf{z}_u)) ]
$$

- VAE의 목적은 average marginal likelihood인 $p(\mathbf{z}_u \mid \mathbf{x}_u) = \int p(\mathbf{x}_u \mid \mathbf{z}_u)p(\mathbf{z}_u)dz $ 를 최대화하는 것이 목적
- $f_\theta (\cdot)$은 신경망이므로 $p(\mathbf{z}_u \mid \mathbf{x}_u)$ 를 유도하는 것이 어렵기 때문에 위의 식인 **ELBO로 근사해서 유도**
- niche item problem을 해결하고자 **focal loss**를 활용하는데, 이는 다음과 같이 정의함

$$
FL(p_t) = -\alpha_t(1-p_t)^\gamma \log(p_t), \quad p_t = 
\begin{cases}
\hat{x}_{ui} & if \quad x_{ui} = 1 \\ 
1 - \hat{x}_{ui} & otherwise
\end{cases}
$$

- 이때, focal loss에 사용되는 $\alpha$와 $\gamma$는 hyperparameter
- 이에 따라 ELBO를 다음과 같이 재정의할 수 있음

$$
\log p \geq \mathbb{E}_q[ \alpha_t(1 - p(\mathbf{x}_u \mid z_u))^{\gamma}\log p(\mathbf{x}_u\mid\mathbf{z}_u) - KL(q(\mathbf{z}_u|\mathbf{x}_u) \Vert p(\mathbf{z}_u)) ]
$$


### VASP

![](/image/paper/vasp/vasp8.png)

- model $m$에 대해서 $m(\cdot) : \mathbf{x}_u \rightarrow \hat{\mathbf{x}}_u$ 로 정의
- 이때 model $m$의 output에는 sigmoid function 처리를 진행해서  $\hat{x}_{uI} \in < 0, 1 > $로 처리
- **$\odot$으로 표시하는 Hadamard product를 활용한 joint learning을 제시함**

$$
m_n(\mathbf{x}_u) = \bigodot^{n}_{j=1}m_j = m_1(\mathbf{x}_u) \odot m_2(\mathbf{x}_u) \odot \cdots \odot m_n(\mathbf{x}_u)
$$

$$
m_n(\mathbf{x}_u) = \hat{x}_{nu} = \bigodot_{j=1}^{n} \hat{x}_{ju} , \quad \hat{x}_{nu} \in \langle 0, 1 \rangle
$$

- 기존의 wide & deep에서 사용한 joint training은 모델의 결과를 합하는 logical OR을 활용하는 반면 VASP에서는 **Hadamard product를 사용한 logical AND** 방식을 사용해서 모델을 결합함
  - Hadamard product를 사용하면 2개의 모델이 모두 동의(1에 근접)해야 값에 의미가 존재함
- 최종적으로 **NEASE와 FLVAE를 element-wise 곱으로 나타냄**

$$
\begin{matrix}
m_{VASP}(\mathbf{x}_u) & = & m_{FLVAE}(\mathbf{x}_u)  \odot m_{EASE}(\mathbf{x}_u) \\
& = & \hat{\mathbf{x}}_{FLVAE_u} \odot \hat{\mathbf{x}}_{EASE_u}
\end{matrix}
$$

$$
\hat{\mathbf{x}}_{EASE_u} = \sigma(W \cdot \mathbf{x}_u)
$$

### Data augmentation

![](/image/paper/vasp/vasp2.png)*Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction*

- 논문 참조 : [Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction](https://arxiv.org/pdf/1611.09842.pdf)
- Autoencoder에서 핵심은 입출력의 과적합을 방지하는 것
- *Split-Brain Autoencoders*에 따르면 gray-scale representation을 학습하는 영역과 color-channel을 학습하는 영역으로 분할되어 훈련을 진행함
- 두 영역은 각각 교차로 예측을 수행하여 원본 사진으로 복구를 함
- 아래는 논문에서 제시한 예시 사진

![](/image/paper/vasp/vasp3.png)*Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction*

- VASP에서는 전처리 단계로 자동화된 data augmentation을 사용하는 1개의 신경망을 활용할 것
- 전체 데이터를 절반으로 나눠서 각자 학습하는 형태로 훈련

![](/image/paper/vasp/vasp9.png)

- 앞서 설명한 Split-Brain Autoencoders: Unsupervised Learning by Cross-Channel Prediction의 아이디어를 사용해서 data augmentation을 진행
- 모든 훈련 epoch마다 input $x_u$를 무작위로 $x_{Au}$와 $x_{Bu}$ 2개의 부분으로 나눔

$$
\begin{aligned}
x_{Aui} = \begin{cases}
0 & if \quad x_{ui} = 0 \\
1 - x_{Bui} & otherwise
\end{cases} \\ 
x_{Bui} = \begin{cases}
0 & if \quad x_{ui} = 0 \\
1 - x_{Aui} & otherwise
\end{cases}
\end{aligned}
$$

- 학습과정에서 $x_{Aui}$와 $x_{Bui}$는 서로 교차로 입출력으로 학습을 진행함

---

## Experimental step

- 실제 구현때 참고할 실험 환경
- 데이터셋은 MovieLens 20M과 Netflix Prize를 활용함
- 전체 데이터의 80%를 학습에 활용하고 20%를 prediction으로 사용
- metric은 NDCG@k와 Recall@k로 진행

### 모델 구현

- Neural EASE
  - kernel constraint를 활용한 대각행렬을 0으로 제한하는 dense layer를 활용
  - 실험과정에서는 loss function을 3개를 활용함 [Neural EASE](#neural-ease) 참고
  - data augmentation이 사용되지 않음
- Variational AE
  - FLVAE는 encoder와 decoder에 모두 dense하게 연결된 residual network를 활용
  - output에는 sigmoid function 사용
  - Data augmentation 사용
  - focal loss hyperparameter $\alpha_t$ = 0.25, $\gamma$ = 2.0을 사용함
- VASP
  - EASE와 FLVAE를 hadamard product를 활용해서 결합
  - hyperparameter는 FLVAE와 동일

### Hyperparameters

- latent space : 2048
- hidden layer : 4096
- encoder
  - 7 residual hidden layer
- decoder
  - 5 residual hidden layer
- epoch : 50
- 초기 세팅
  - learning rate : 0.00005
  - bath size : 1024
- 이후 learning rate 0.00001로 낮추고 20 epochs 추가 학습
- 이후 learning rate 0.000001로 낮추고 20 epochs 추가 학습
