<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review" /><meta property="og:locale" content="en" /><meta name="description" content="DL Basic : Introcution &amp; Historical Review" /><meta property="og:description" content="DL Basic : Introcution &amp; Historical Review" /><link rel="canonical" href="https://cow-coding.github.io/posts/day13_1_history/" /><meta property="og:url" content="https://cow-coding.github.io/posts/day13_1_history/" /><meta property="og:site_name" content="Coding Gallery" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-02-07T10:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="TXb5nWUV5Ag0O8EVGMTUS11ZVi7BYOensPMiRdQGNRg" /> <script type="application/ld+json"> {"description":"DL Basic : Introcution &amp; Historical Review","url":"https://cow-coding.github.io/posts/day13_1_history/","@type":"BlogPosting","headline":"[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review","dateModified":"2022-05-16T14:24:47+09:00","datePublished":"2022-02-07T10:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cow-coding.github.io/posts/day13_1_history/"},"@context":"https://schema.org"}</script><title>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review | Coding Gallery</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Coding Gallery"><meta name="application-name" content="Coding Gallery"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4761810170892865" crossorigin="anonymous"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/my_img/icebear.jpeg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Coding Gallery</a></div><div class="site-subtitle font-italic">마침표를 찍고 조금 더 멀리</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/cow-coding" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['kbp0237','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/cow-coding">Park Kibum</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2022-02-07 10:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Mon, Feb 7, 2022, 10:00 AM +0900" >Feb 7, 2022</em> </span> <span> Updated <em class="timeago" date="2022-05-16 14:24:47 +0900 " data-toggle="tooltip" data-placement="bottom" title="Mon, May 16, 2022, 2:24 PM +0900" >May 16, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1607 words"> <em>8 min</em> read</span></div></div></div><div class="post-content"><h1 id="dl-basic--introcution--historical-review">DL Basic : Introcution &amp; Historical Review</h1><hr /><h2 id="딥러닝의-기본요소">딥러닝의 기본요소 <a href="#딥러닝의-기본요소" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Data<ul><li>데이터는 “어떤 문제를 해결할 것인가?”에 따라 형식이 달라짐</ul><li>Model<ul><li>모델의 성질에 따라 동일한 데이터라도 다른 성능을 보인다.<li>심지어 같은 task를 해결하기 위해서도 모델에 쓰이는 Technique들이 다양하다.</ul><li>Loss Function<ul><li>모델과 데이터가 정해졌을 때 어떻게 모델을 학습할 지를 결정하는 요소이다.<li>Neural Net의 weight 조정을 할 때 사용<li><code class="language-plaintext highlighter-rouge">MSE</code>, <code class="language-plaintext highlighter-rouge">CE</code>, <code class="language-plaintext highlighter-rouge">MLE</code>와 같은 다양한 loss function이 있는데, 이는 문제의 유형에 맞춰 선택한다. 하지만 loss function이 줄어드는 것이 반드시 좋은 결과를 말할 수는 없다. 또한 데이터의 특성에 맞춰 loss function을 다르게 결정할 필요도 있다.</ul><li>Optimiztion Algorithm<ul><li>위의 모든 것들이 결정된 후 네트워크를 어떻게 줄일지를 결정하는 역할을 한다.<li>1차 미분을 활용한 SGD 접근법을 활용하였지만 성능이 좋지 않아 다른 방식도 사용<li><code class="language-plaintext highlighter-rouge">Momentum</code>, <code class="language-plaintext highlighter-rouge">NAG</code>, <code class="language-plaintext highlighter-rouge">Adagrad</code>, <code class="language-plaintext highlighter-rouge">Adadelta</code>, <code class="language-plaintext highlighter-rouge">Rmsprop</code>와 같은 방식들을 사용하게된다.<li>추가적으로 regularizer들을 활용하기도 한다.</ul></ul><h2 id="historical-review">Historical Review <a href="#historical-review" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p>Denny Britz가 2020년에 발표한 <a href="https://dennybritz.com/blog/deep-learning-most-important-ideas.pdf"><em>Deep Learning’s Most Important Ideas - A Brief Historical Review</em></a>에는 2020년까지의 주요 Deep Learning 논문들의 review가 담겨있다. 이를 간단하게 정리하겠다.</p><h3 id="alexnet-2012">AlexNet (2012) <a href="#alexnet-2012" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/alexnet.png" alt="AlexNet" width="600" data-proofer-ignore></p><p>그림에서 알 수 있듯이 CNN이다. <em>AlexNet</em>이 탄생한 것은 224 X 224의 이미지를 분류하는 대회인 ILSVRC였다. 지금보면 왜 평범한 CNN이 딥러닝의 역사를 바꾼 것의 맨 처음을 장식하는 것일까? 라는 생각을 할 수 있는데 사실 AlexNet은 평범한 CNN은 아니었다.<br /> AlexNet이 나오기 이전, ILSVRC의 우승 모델은 DL 기반의 모델들이 아닌 커널기반, SVM과 같은 고전방식을 활용했다. AlexNet의 등장으로 최초의 DL 모델이 우승을 차지했고 이후 대 Deep Learning 시대가 열리게 되었다.<br /> 단순히 “되겠지~”라고만 여겨지던 딥러닝이 드디어 Machine Learning에서 빛을 보이며 실력을 발휘하게 된 역사적인 사건이다.</p><h3 id="dqn-2013">DQN (2013) <a href="#dqn-2013" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/dqn.png" alt="DQN" width="600" data-proofer-ignore></p><p>지난 2016년에 있었던 역사적인 사건인 알파고 VS 이세돌의 시작인 DQN이다. DQN은 알파고를 개발한 딥마인드의 연구결과인데, 아타리라는 블록깨기 게임을 인공지능 모델 스스로 학습을 통해 해결하는 <strong>강화학습</strong>으로 풀어낼 때 사용한 방식이다. 사실 Q-Learning이라는 방식은 이전에 사용이 되었는데 이를 deep learning과 접목시킨 방식으로 학습을 한 것이다. DQN 연구로 구글이 딥마인드를 인수했다는 설도…</p><h3 id="encoder--decoder-2014">Encoder / Decoder (2014) <a href="#encoder--decoder-2014" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/encoder.png" alt="Encode/Decoder" width="600" data-proofer-ignore></p><p>Encoder와 Decoder는 NLP에서 translation 문제를 해결하고자 나타났다. 다른 언어의 문장을 또 다른 언어의 문자으로 바꿔야하는 것이다. 즉 특정 Sequence를 다른 Sequence로 변환하는 작업을 하는 것이다. 결과적으로 Sequence-to-sequence(Seq-2-Seq)를 할 수 있게되었고 NLP분야의 발전이 일어났다.</p><h3 id="adam-2014">Adam (2014) <a href="#adam-2014" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/adam.png" alt="Adam" width="600" data-proofer-ignore></p><p>Adam이다. ML/DL을 공부하는 사람 중 과연 Adam을 한번도 못 들어는 봤어도 한번만 본 사람은 없을 것이다. 그만큼 Adam optimizer는 가장 많이 사용되는 optimizer이고 준수한 성능을 낸다. 가장 통용적으로 많이 사용되는 optimizer가 등장한 것이다.</p><h3 id="gan-2015">GAN (2015) <a href="#gan-2015" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/gan.png" alt="GAN" width="600" data-proofer-ignore></p><p>GAN은 어떻게보면 DL에서 가장 중요한 것 중 하나라고 말할 수 있다. Network가 스스로 학습데이터를 만들어서 학습을 하게 된 것이다.</p><h3 id="resnet--residual-network-2015">ResNet : Residual Network (2015) <a href="#resnet--residual-network-2015" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/resnet.png" alt="ResNet" width="600" data-proofer-ignore></p><p>기존의 딥러닝은 많은 층의 network를 쌓게되면 오히려 성능이 떨어지게 되었다. 이름은 깊게 쌒았다는 의미의 딥러닝인데 정작 많이 쌓으면 성능이 떨어진다니… 하지만 ResNet이 나타나며 이전보다 깊은 수의 네트워크를 설정해도 overfitting이나 underfitting문제가 덜 발생하게 해주며 딥러닝이 이름 그대로의 값을 하게 되었다.</p><h3 id="transformer-2017">Transformer (2017) <a href="#transformer-2017" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/transformer.png" alt="transfomer" width="300" data-proofer-ignore></p><p>Transformer가 등장하면서 기존의 RNN의 분야에서 RNN을 대체하게되었다. 하지만 이는 겨우 시작에 불과하였고 이제는 transfomer가 다른 분야에까지 사용되면서 CV영역까지 넘어오고있다.</p><h3 id="bert-2018">BERT (2018) <a href="#bert-2018" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/bert.png" alt="bert" width="600" data-proofer-ignore></p><p>앞서서 이미지 분류(Image Classification), 강화학습(Reinforcement Learning)의 패러다임을 일으킨 연구를 알아봤다. BERT는 대표 분야 중 하나인 NLP(Natural Language Processe)의 가장 큰 패러다임 변화를 일으킨 연구이다. 많은 사람들이 NLP는 BERT 이전과 이후로 나눈다고 많이들 말하는데, 솔직히 개인적으로 써본 결과도 굉장히 압도적인 성능을 보였다.<br /> Fine-tuned NLP model이라고 하는데, 문제해결을 위한 학습 데이터가 많지 않을 때 일반적으로 주어진 큰 규모의 corpus를 활용하여 pre-training을 진행하고 해결하고자하는 데이터를 해당 모델에 fine-tuning을 하는 것이다.</p><h3 id="big-language-models--gpt-x-2019">Big Language Models : GPT-X (2019) <a href="#big-language-models--gpt-x-2019" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/GPT-3.png" alt="" width="600" data-proofer-ignore></p><p>BERT의 최종 형태라고도 하는 GPT-X이다. Big Language Model이라고 하는데, 이는 parameter 개수가 굉장히 많아서 붙어진 이름이다.<br /> GPT-3의 등장으로 NLP의 연구는 굉장히 발전하게되었다.</p><h3 id="self-supervised-learning-2020">Self-supervised Learning (2020) <a href="#self-supervised-learning-2020" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/precourse/SimCLR.png" alt="" width="600" data-proofer-ignore></p><p>모델을 학습할 때는 라벨이 붙은 데이터를 활용하는 것이 중요하다. 하지만 이는 cost가 많이 소요되는 작업이다. 이를 해결하고자 unlabled data를 활용해서 학습에 사용하는 것이다. 하지만 unsupervised와는 다르게 모델이 스스로 label을 형성하기 때문에 self supervised learning이라고 붙었다고 한다. <del>이해가 맞는지 모르겠음 ㅠㅠ</del></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/naver-boostcamp-ai-tech/'>NAVER BoostCamp AI Tech</a>, <a href='/categories/level-1-dl-basic/'>Level 1 - DL Basic</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/deep-learning/" class="post-tag no-text-decoration" >Deep Learning</a> <a href="/tags/naver/" class="post-tag no-text-decoration" >NAVER</a> <a href="/tags/boostcamp/" class="post-tag no-text-decoration" >BoostCamp</a> <a href="/tags/ai-tech/" class="post-tag no-text-decoration" >AI Tech</a> <a href="/tags/dl-basic/" class="post-tag no-text-decoration" >DL Basic</a> <a href="/tags/dl/" class="post-tag no-text-decoration" >DL</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review - Coding Gallery&url=https://cow-coding.github.io/posts/day13_1_history/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review - Coding Gallery&u=https://cow-coding.github.io/posts/day13_1_history/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Historical Review - Coding Gallery&url=https://cow-coding.github.io/posts/day13_1_history/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/coursera2_3/">[MLOps Specialization / Step2] Labeling Data</a><li><a href="/posts/module/">[BoostCamp AI Tech / 심화포스팅] torch.nn.Module 뜯어먹기</a><li><a href="/posts/list/">[Deep Dive Python] 2. List</a><li><a href="/posts/variable/">[Deep Dive Python] 1. Python의 객체와 변수 개념</a><li><a href="/posts/final7/">[BoostCamp AI Tech / Final] Day91 - Airflow setting 및 배치 파이프라인 설계</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai-tech/">AI Tech</a> <a class="post-tag" href="/tags/boostcamp/">BoostCamp</a> <a class="post-tag" href="/tags/naver/">NAVER</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/mlops/">MLOps</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/basic/">Basic</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/recommender-system/">Recommender System</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/day13_2_mlp/"><div class="card-body"> <em class="timeago small" date="2022-02-07 13:00:00 +0900" >Feb 7, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - MLP (Multi-Layer Perceptron)</h3><div class="text-muted small"><p> DL Basic : MLP (Multi-Layer Perceptron) Neural Networks 일반적으로 Neural Netwrok라고 하면 인간의 뇌 구조를 모방해서 만든 시스템이라고 생각함 하지만 우리의 비행기가 새를 모방했다고 하지만 새와는 다른 것처럼 Neural Net이 정확하게 인간의 뇌를 구현한 것이라 보긴 어려움 ...</p></div></div></a></div><div class="card"> <a href="/posts/day13_3_optimization/"><div class="card-body"> <em class="timeago small" date="2022-02-07 13:00:00 +0900" >Feb 7, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - Optimization</h3><div class="text-muted small"><p> DL Basic : Optimization Introduction Model 학습의 기본적인 원리는 Gradient Descent Gradient Descent는 1차 미분의 결과의 최적화 알고리즘 1차 미분 결과의 최적화는 local minimum을 찾는 것 Important Concepts ...</p></div></div></a></div><div class="card"> <a href="/posts/day14_1_cnn/"><div class="card-body"> <em class="timeago small" date="2022-02-08 13:00:00 +0900" >Feb 8, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[BoostCamp AI Tech / Level 1 - DL Basic] Day14 - Convolutional Neural Networks</h3><div class="text-muted small"><p> DL Basic : Convolutional Neural Networks Convolution convolution 연산은 기본적으로 Input에 대해 커널단위로 연산을 하는 것을 의미 특징 추출을 목적으로 할 때 많이 사용함 필터(kernel)의 종류에 따라 다른 결과가 나타남 ex) convolution ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/day12/" class="btn btn-outline-primary" prompt="Older"><p>[BoostCamp AI Tech] Day12</p></a> <a href="/posts/day13_2_mlp/" class="btn btn-outline-primary" prompt="Newer"><p>[BoostCamp AI Tech / Level 1 - DL Basic] Day13 - MLP (Multi-Layer Perceptron)</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://cow-coding.github.io/posts/day13_1_history/'; this.page.identifier = '/posts/day13_1_history/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://cow-coding.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (typeof modeToggle !== "undefined") { /* modeToggle.addEventListener('click', reloadDisqus); // not pretty for 'color-scheme' */ window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/cow-coding">Park Kibum</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai-tech/">AI Tech</a> <a class="post-tag" href="/tags/boostcamp/">BoostCamp</a> <a class="post-tag" href="/tags/naver/">NAVER</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/mlops/">MLOps</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/basic/">Basic</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/recommender-system/">Recommender System</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { loader: {load: ['[tex]/color']}, chtml: { scale: 1.2 }, tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ], packages: {'[+]':['color']} } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-163727422-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-163727422-1'); }); </script>
