<!DOCTYPE html><html lang="en" data-mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="day-prompt" content="days ago"><meta name="hour-prompt" content="hours ago"><meta name="minute-prompt" content="minutes ago"><meta name="justnow-prompt" content="just now"><meta name="generator" content="Jekyll v4.2.1" /><meta property="og:title" content="[Paper Review] Neural Graph Collaborative Filtering (2019)" /><meta property="og:locale" content="en" /><meta name="description" content="Neural Graph Collaborative Filtering (2019)" /><meta property="og:description" content="Neural Graph Collaborative Filtering (2019)" /><link rel="canonical" href="https://cow-coding.github.io/posts/ngcf/" /><meta property="og:url" content="https://cow-coding.github.io/posts/ngcf/" /><meta property="og:site_name" content="Coding Gallery" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-03-14T13:00:00+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="[Paper Review] Neural Graph Collaborative Filtering (2019)" /><meta name="twitter:site" content="@twitter_username" /><meta name="google-site-verification" content="TXb5nWUV5Ag0O8EVGMTUS11ZVi7BYOensPMiRdQGNRg" /> <script type="application/ld+json"> {"description":"Neural Graph Collaborative Filtering (2019)","url":"https://cow-coding.github.io/posts/ngcf/","@type":"BlogPosting","headline":"[Paper Review] Neural Graph Collaborative Filtering (2019)","dateModified":"2022-03-14T13:00:00+09:00","datePublished":"2022-03-14T13:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cow-coding.github.io/posts/ngcf/"},"@context":"https://schema.org"}</script><title>[Paper Review] Neural Graph Collaborative Filtering (2019) | Coding Gallery</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Coding Gallery"><meta name="application-name" content="Coding Gallery"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4761810170892865" crossorigin="anonymous"></script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end" lang="en"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/my_img/icebear.jpeg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Coding Gallery</a></div><div class="site-subtitle font-italic">마침표를 찍고 조금 더 멀리</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <a href="https://github.com/cow-coding" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['kbp0237','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>[Paper Review] Neural Graph Collaborative Filtering (2019)</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>[Paper Review] Neural Graph Collaborative Filtering (2019)</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/cow-coding">Park Kibum</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" date="2022-03-14 13:00:00 +0900" data-toggle="tooltip" data-placement="bottom" title="Mon, Mar 14, 2022, 1:00 PM +0900" >Mar 14, 2022</em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2746 words"> <em>15 min</em> read</span></div></div></div><div class="post-content"><h1 id="neural-graph-collaborative-filtering-2019">Neural Graph Collaborative Filtering (2019)</h1><hr /><h2 id="논문-소개">논문 소개 <a href="#논문-소개" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><p><img data-src="/image/boostcamp/recsys/deep/ngcf.png" alt="" data-proofer-ignore><em>출처 : ACM2019 Neural Graph Collaborative Filtering</em></p><center> <a href="https://arxiv.org/abs/1905.08108"><bold>[ACM 2019] Neural Graph Collaborative Filtering</bold></a> </center><p><br /></p><p>NGCF는 GNN의 최초 등장 논문은 아닙니다. 이전에 이미 GNN에 대한 개념이 존재했었고 어느정도 연구도 있었습니다. 하지만 추천 시스템에 적용하여 효과적인 성능을 보여줬으며 이후 GNN을 활용한 추천 시스템 연구에 도화선 역할을 하게 되었습니다.<br /> 이후 LightGCN 등 여러가지 GNN을 활용한 추천 시스템 연구들이 등장하였습니다. 이번 포스팅에서는 지난 AlexNet과는 다르게 핵심적인 NGCF이론 위주로 설명하겠습니다.<br /> <del>지난번에 알렉스넷 해석처럼 리뷰했다가 반나절 걸려서 그렇게는 못 하겠습니다…</del></p><hr /><h2 id="abstract">Abstract <a href="#abstract" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>최신 추천 시스템 연구는 item과 유저의 벡터 표현 (임베딩)을 학습하는 방식을 활용함<li>MF나 딥러닝이 적용된 방식은 ID나 attribute 같은 유저(아이템)의 속성을 활용해서 임베딩을 했음<li>이런 임베딩 방식은 유저-아이템 상호작용인 <strong>collaborative signal</strong>을 임베딩 과정에서 인코딩 하지 않는다는 문제가 존재함<li>이 논문에서는 이분 그래프 구조의 user-item 상호작용을 임베딩 과정에 포함하는 방법을 제시함<li>user-item graph 구조를 임베딩 전파를 통해 전달하는 NGCF를 개발<li>이때, user-item graph는 <strong>high-order connectivity</strong>를 사용해서 표현하고 전달함</ul><hr /><h2 id="introduction">Introduction <a href="#introduction" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="문제제기">문제제기 <a href="#문제제기" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li>논문은 기존 CF의 연산 방식의 핵심을 다음과 같이 정의<ol><li>유저-아이템 임베딩 : latent factor<li>상호작용의 모델링 : $P^\intercal Q$ (dot product를 통한 선형연산)</ol><li>기존 CF에는 <strong>상호작용 표현의 한계</strong>가 존재함<ul><li>이런 한계가 존재하는 이유는 기존 CF (MF, NCF)의 연산 순서때문<li>$\mathbf{e}_u = P$, $\mathbf{e}_i = Q$ 로 유저와 아이템을 임베딩하고 두 임베딩 matrix의 inner product인 $P^\intercal Q$ 순서로 연산<li>이 과정을 보면 각각 임베딩 후 상호작용을 연산하므로 <strong>유저-아이템의 상호작용 자체를 전달하지 못하는</strong> 한계가 발생함 (latent 형태로 연산하므로 정보의 누락 발생)</ul><li>이런 기존 CF의 문제를 interaction function ($P^\intercal Q$)에만 의존하므로 sub-optimal(누락된 부분 정보)한 임베딩을 사용한다고 제시</ul><hr /><h3 id="문제-해결-아이디어">문제 해결 아이디어 <a href="#문제-해결-아이디어" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="https://github.com/cow-coding/Machine-Learning-Paper-Review-and-Implementation/blob/main/images/NGCF/figure1.png?raw=true" alt="" width="500" data-proofer-ignore><em>Neural Graph Collaborative Filtering</em></p><ul><li>논문에서 계속 언급하는 <strong>Collaborative Signal</strong>은 유저-아이템 상호작용(소비관계)을 의미<li>좌측은 기존 CF방식의 상호작용 표현방식인데, 이 방법은 유저와 아이템 수가 늘어날수록 연결되지 않은 다른 item의 간접적인 상호작용 표현에 한계가 존재함<li><strong>GNN을 활용하여 유저-아이템 상호작용은 임베딩 부분에서 처리</strong>하는 방식을 제시<li><strong>High-order Connectivity</strong>를 사용하면 직/간접적 상호작용을 표시할 수 있음<ul><li>GNN을 사용하면 <strong>user-item-user 연결관계</strong>로 따로 유사도를 계산하지 않아도 user간의 연결관계로 유사도를 파악할 수 있음<li>Graph로 관계를 표현하면 <strong>$u_1$에 대한 아이템의 추천 강도도 계산</strong>할 수 있음<ul><li>$i_4$는 $i_4 \rightarrow u_2 \rightarrow i_2 \rightarrow u_1$ path와 $i_4 \rightarrow u_3 \rightarrow i_3 \rightarrow u_1$ path, 총 2가지 경로로 $u_1$에게 전달됨<li>$i_5$가 $u_1$에게 전달되는 경로는 1개밖에 없으므로 추천 강도는 $i_4 &gt; i_5$가 됨</ul></ul></ul><hr /><h2 id="methodology">Methodology <a href="#methodology" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="ngcf-구조">NGCF 구조 <a href="#ngcf-구조" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="/image/boostcamp/recsys/deep/ngcf2.png" alt="" width="500" data-proofer-ignore><em>Neural Graph Collaborative Filtering</em></p><ul><li>NGCF 모델 구조는 크게 3개의 레이어로 구성됨<ul><li>Embedding Layer<ul><li>one-hot encoding의 유저-아이템 초기 임베딩을 k 차원 임베딩으로 변환</ul><li><strong>Embedding Propagation Layer</strong><ul><li>NGCF에서 가장 중요한 레이어<li>유저-아이템 연결관계를 갖는 high-order connectivity를 학습하는 레이어</ul><li>Prediction Layer<ul><li>아이템, 유저 각 전파 레이어에서 전달된 임베딩을 concat해서 결과 score를 연산</ul></ul></ul><h3 id="embedding-layer">Embedding Layer <a href="#embedding-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3>\[\mathbf{E} = [ \; \underbrace{\mathbf{e}_{u_1}, \cdots, \mathbf{e}_{u_N}}_{\text{users embeddings}} , \underbrace{\mathbf{e}_{i_1}, \cdots, \mathbf{e}_{i_M}}_{\text{item embeddings}} \;]\]<ul><li>embedding을 생성하는 레이어<li>임베딩 방식은 기존의 CF방식 (MF, Neural CF)과 동일하지만 기존 CF는 이걸 바로 interaction function에 입력함<li>NGCF는 <strong>GNN에 임베딩을 전파하여 refine</strong><ul><li>Collaborative Signal(상호작용)을 직접적으로 레이어에 전달하는 과정</ul></ul><h3 id="embedding-propagation-layer">Embedding Propagation Layer <a href="#embedding-propagation-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><h4 id="first-order-propagation">First-order Propagation <a href="#first-order-propagation" class="anchor"><i class="fas fa-hashtag"></i></a></h4></h4><ul><li>collaborative signal을 전달할 <strong>message</strong>를 구성하고 결합하는 단계</ul>\[\mathbf{m}_{u\leftarrow i} = f(\mathbf{e}_i, \mathbf{e}_u, p_{ui}) = \frac{1}{\sqrt{ \left\vert\mathcal{N}_{u}\right\vert \left\vert\mathcal{N}_{i}\right\vert }}\left( \mathbf{W}_1\mathbf{e}_i + \mathbf{W}_2 (\mathbf{e}_i \odot \mathbf{e}_u) \right)\]<ul><li><strong>Message Construction 단계</strong>는 유저-아이템간의 affinity(밀접관계)를 표현하는 message를 형성함<li>$\mathbf{e}_i \odot \mathbf{e}_u$에서 $\odot$은 element-wise 연산인데, element-wise 연산 특성상 두 벡터 연결관계와 강도를 잘 표현함 (interaction term)<li>$p_{ui}$는 연결 item이 과도하게 많을 경우를 방지하는 decay factor<ul><li>주변 이웃 노드 수($\left\vert \mathcal{N} \right\vert$)로 나눠서 normalize함</ul></ul>\[\mathbf{e}_{u}^{(1)} = \text{LeakyReLU}\left( \mathbf{m}_{u \leftarrow u} + \sum_{i \in \mathcal{N}_{u}} \mathbf{m}_{u \leftarrow i} \right)\]<ul><li><strong>Message Aggregation 단계</strong>는 $u$의 이웃 노드들에서 전파된 message를 결합하여 해당 유저의 1단(1 layer) 임베딩을 형성함<li>$\text{LeakyReLU}$를 사용한 이유는 collaborative signal에서 긍정과 부정 정보를 모두 인코딩해야 하기 때문<li>정보의 손실을 방지하고자 self-connection term ($\mathbf{m}_{u \leftarrow u}$)를 추가함<ul><li>이걸 추가하는 이유는 GCN에서 그래프를 표현하는 방식때문임</ul></ul><details> <summary>왜 self-connection term이 필요한가?</summary><div><p>self-connection항이 들어가는 이유는 본 논문에서 제시하는 그래프 표현 방식때문입니다. 일반적으로 그래프를 표현할 때 앞서 말한 것처럼 인접행렬의 형태를 사용하려고 합니다. 아래 그래프로 예를 들어봅시다.</p><p><img data-src="/image/boostcamp/recsys/deep/graph1.png" alt="" data-proofer-ignore></p>\[\text{Adjacency matrix}(\mathbf{A}) = \begin{bmatrix} 0 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 \end{bmatrix} \quad \text{Degree matrix}(\mathbf{D}) = \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix}\]<p>문제는 단순히 인접행렬만으로 표현하면 특정 노드에 인접한 노드의 개수(차수)를 $O(1)$시간에 알기에 무리가 있습니다. 그래서 그래프 표현에 Degree matrix를 추가해서 표현합니다. 문제는 두 행렬이 따로 존재하면 여러가지 의미로 효율성이 떨어집니다. 그래서 이 두 행렬의 정보가 서로 공존하게 만드는 <strong>Laplacian Matrix (라플라시안 행렬)</strong> 을 만듭니다. (<a href="https://en.wikipedia.org/wiki/Laplacian_matrix">wikipedia : laplacian matrix</a>)</p>\[\mathcal{L} = \text{Degree matrix} - \text{Adjacency matrix} = \begin{bmatrix} 1 &amp; -1 &amp; 0 \\ -1 &amp; 2 &amp; -1 \\ 0 &amp; -1 &amp; 1 \end{bmatrix}\]<p>이렇게 만들어진 라플라시안 행렬은 일반적으로 대각성분이 모두 1인 <strong>Normalized Laplacian Matrix</strong>로 변환합니다.</p>\[\mathcal{L}^{\text{norm}} = \mathbf{D}^{-\frac{1}{2}}\mathcal{L}\mathbf{D}^{-\frac{1}{2}} = \begin{bmatrix} 1 &amp; -\frac{1}{\sqrt{2}} &amp; 0 \\ -\frac{1}{\sqrt{2}} &amp; 1 &amp; -\frac{1}{\sqrt{2}} \\ 0 &amp; -\frac{1}{\sqrt{2}} &amp; 1 \end{bmatrix}\]<p>그래서 <strong>원래는</strong> 대각성분이 모두 1로 존재하기 때문에 self-connection이 필요하지 않습니다. (아마도요….)<br /> <strong>근데</strong> 본 논문에서는 모델의 계산 편의성을 위해 대각원소를 모두 0으로 처리한 matrix로 정의했습니다. 그래서 self-connection term이 필요합니다.</p>\[\mathcal{L}^{\text{norm}} = \mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}} \text{ and } \mathbf{A} = \begin{bmatrix} \mathbf{0} &amp; \mathbf{R} \\ \mathbf{R}^\intercal&amp; \mathbf{0} \end{bmatrix} \quad (\text{Paper's Laplacian})\]<p>여기서 $\mathbf{R}$은 user-item intercation matrix 입니다.</p></div></details><h4 id="high-order-propagation">High-order Propagation <a href="#high-order-propagation" class="anchor"><i class="fas fa-hashtag"></i></a></h4></h4><p><img data-src="/image/boostcamp/recsys/deep/ngcf3.png" alt="" data-proofer-ignore><em>Neural Graph Collaborative Filtering</em></p><ul><li>1개의 레이어는 1개의 order를 처리함<li>따라서 $l$개의 embedding propagation layer를 쌓으면 <strong>유저노드는 $l$ 거리만큼 떨어진 이웃의 메시지</strong>를 사용할 수 있음<ul><li>이런 이웃들을 $l$-hop neighbor라고 함</ul><li>수식적으로 $l$ layer에서 생성된 message는 아래와 같이 나타냄</ul>\[\mathbf{e}_{u}^{(l)} = \text{LeakyReLU}\left( \mathbf{m}^{(l)}_{u \leftarrow u} + \sum_{i \in \mathcal{N}_{u}} \mathbf{m}^{(l)}_{u \leftarrow i} \right)\] \[\begin{cases} \mathbf{m}^{(l)}_{u\leftarrow i} = p_{ui} \left( \mathbf{W}^{(l)}_1\mathbf{e}^{(l-1)}_i + \mathbf{W}^{(l)}_2 (\mathbf{e}^{(l-1)}_i \odot \mathbf{e}^{(l-1)}_u) \right) \\ \mathbf{m}^{(l)}_{u\leftarrow u} = \mathbf{W}^{(l)}_1\mathbf{e}^{(l-1)}_u \end{cases}\]<ul><li>최종적으로 위의 식의 계산은 아래 수식을 통해 구현되어 실제 처리됨</ul>\[\mathbf{E}^{(l)} = \text{LeakyReLU}\left( (\mathcal{L} + \mathbf{I})\mathbf{E}^{(l-1)}\mathbf{W}^{(l)}_1 + \mathcal{L}\mathbf{E}^{(l-1)} \odot\mathbf{E}^{(l-1)}\mathbf{W}^{(l)}_2 \right)\]<ul><li>솔직히 굉장히 뭐가 많이 튀어나와서 정신이 없을텐데 여기서 살짝 첨언을 하자면 도대체 저 $\mathcal{L}$은 어디서 갑자기 튀어 나온건가..?하면 $\mathbf{e}^{(l)}_u$ 식을 자세히 보면 내부에 크게 2개의 항으로 나뉜다.<ul><li>$\mathbf{m}^{(l)}_{u \leftarrow u}$ : self-connection<ul><li>이 항을 계산할 때는 자기 자신 노드에 대한 연산만 하기 때문에 굳이 user-item interaction을 생각할 필요가 없다. 그래서 그냥 identity matrix를 곱한다.</ul><li>$\mathbf{m}^{(l)}_{u\leftarrow u}$ : user-item interaction<ul><li>문제는 이 항에서는 user-item interaction을 고려해야한다. 따라서 앞에서 user-item 관계를 담고 있는 그래프 정보인 $\mathcal{L}$을 곱해주는 것이다.</ul><li>이해가 잘 안되면 $\mathbf{E}^{(l)}$랑 $\mathbf{e}^{(l)}_u$를 그냥 다 전개해서 나란히 두고 비교해보면 어느정도 느낌이 날 것이다. <del>별로 안 복잡하다.</del></ul></ul><h3 id="prediction-layer">Prediction Layer <a href="#prediction-layer" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3>\[\begin{aligned} \mathbf{e}^{*}_u = \mathbf{e}^{(0)}_u \Vert \cdots \Vert \mathbf{e}^{(L)}_u , \quad \mathbf{e}^{*}_i = \mathbf{e}^{(0)}_i \Vert \cdots \Vert \mathbf{e}^{(L)}_i \\\\ \hat{y}_\text{NGCF}(u, i) = {\mathbf{e}^{*}_u}^\intercal\mathbf{e}^{*}_i \qquad\quad\quad \end{aligned}\]<ul><li>L번째 layer까지 임베딩 벡터를 형성했으면 user, item 별로 각각 concatenate하여 최종 임베딩 벡터를 생성함<li>그리고 각 임베딩 벡터를 내적해서 최종 선호도를 계산</ul><h3 id="optimization">Optimization <a href="#optimization" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3>\[\textit{Loss} = \sum_{(u, i, j)\in \mathcal{O}} -\ln\sigma(\hat{y}_{ui} - \hat{y}_{uj}) + \lambda \lVert \Theta \rVert^2_2 , \quad \Theta = \{ \mathbf{E}, \{ \mathbf{W}^{(l)_1}, \mathbf{W}^{(l)}_2 \}^L_{l=1} \}\]<ul><li>loss function은 이전에 BPR에서 사용된 BPR loss를 사용<li>BPR loss의 수식구조에 따라 $\mathcal{O} = { (u, i, j) \mid (u, i) \in \mathcal{R}^+, (u, j) \in \mathcal{R}^- }$이 되는데, $\mathcal{R}^+$는 관측한 상호관계이고 $\mathcal{R}^-$는 비관측 상호관계를 의미<li>activation function은 sigmoid<li>$\lambda$는 $L_2$ regularization으로 오버피팅 방지<li>optimizer는 Mini-batch Adam 사용</ul><h3 id="dropout">Dropout <a href="#dropout" class="anchor"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li><strong>Message Dropout</strong><ul><li>layer에서 생성된 message 중 일부를 dropout<li>user와 item의 단일 연결관계의 존재 여부에 더 강한 robustness를 임베딩해주는 효과</ul><li><strong>Node Dropout</strong><ul><li>특정 노드를 임의로 차단하고 모든 출력 message를 차단<li>$l$번째 전파 레이어에서 라플라시안 행렬의 노드들 중 임부를 임의로 drop<li>특정 user-item 관계에 대한 영향을 줄여줌</ul></ul><hr /><h2 id="conclusion">Conclusion <a href="#conclusion" class="anchor"><i class="fas fa-hashtag"></i></a></h2></h2><ul><li>Embedding propagation layer가 많을수록 성능이 좋아짐<li>다만 너무 많으면 오버피팅 발생하므로 3~4개 층이 가장 최적 성능<li>Embedding propagation으로 representation을 좀 더 정확하게 해줬기 때문에 수렴속도와 recall에서 좋은 효과를 보임<li>또한 유저-아이템 임베딩 공간이 더 명확하게 구분됨</ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/paper-review/'>Paper Review</a>, <a href='/categories/recommender-system/'>Recommender System</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/naver/" class="post-tag no-text-decoration" >NAVER</a> <a href="/tags/boostcamp/" class="post-tag no-text-decoration" >BoostCamp</a> <a href="/tags/ai-tech/" class="post-tag no-text-decoration" >AI Tech</a> <a href="/tags/gnn/" class="post-tag no-text-decoration" >GNN</a> <a href="/tags/ngcf/" class="post-tag no-text-decoration" >NGCF</a> <a href="/tags/paper-review/" class="post-tag no-text-decoration" >paper review</a> <a href="/tags/recommender-system/" class="post-tag no-text-decoration" >recommender system</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=[Paper Review] Neural Graph Collaborative Filtering (2019) - Coding Gallery&url=https://cow-coding.github.io/posts/ngcf/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=[Paper Review] Neural Graph Collaborative Filtering (2019) - Coding Gallery&u=https://cow-coding.github.io/posts/ngcf/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=[Paper Review] Neural Graph Collaborative Filtering (2019) - Coding Gallery&url=https://cow-coding.github.io/posts/ngcf/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/coursera2_3/">[MLOps Specialization / Step2] Labeling Data</a><li><a href="/posts/module/">[BoostCamp AI Tech / 심화포스팅] torch.nn.Module 뜯어먹기</a><li><a href="/posts/list/">[Deep Dive Python] 2. List</a><li><a href="/posts/variable/">[Deep Dive Python] 1. Python의 객체와 변수 개념</a><li><a href="/posts/final7/">[BoostCamp AI Tech / Final] Day91 - Airflow setting 및 배치 파이프라인 설계</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai-tech/">AI Tech</a> <a class="post-tag" href="/tags/boostcamp/">BoostCamp</a> <a class="post-tag" href="/tags/naver/">NAVER</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/mlops/">MLOps</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/basic/">Basic</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/recommender-system/">Recommender System</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/VASP/"><div class="card-body"> <em class="timeago small" date="2022-04-04 13:00:00 +0900" >Apr 4, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[Paper Review] Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP)</h3><div class="text-muted small"><p> Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP) (2021) 논문 소개 출처 : Deep Variational Autoencoder with Shallow Parallel Path for Top-N Recommendation (VASP)...</p></div></div></a></div><div class="card"> <a href="/posts/day36_recsys1/"><div class="card-body"> <em class="timeago small" date="2022-03-14 15:00:00 +0900" >Mar 14, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[BoostCamp AI Tech / RecSys] Day36 - RecSys with GNN</h3><div class="text-muted small"><p> RecSys : Recommender System with Graph Neural Net Neural Graph Collaborative Filtering의 자세한 내용은 Paper Review 카테고리에 있습니다. Graph Neural Network Graph 점(node)과 간선(edge)으로 구성된 자료구조 일반적으로 $...</p></div></div></a></div><div class="card"> <a href="/posts/alexnet/"><div class="card-body"> <em class="timeago small" date="2022-02-09 00:00:00 +0900" >Feb 9, 2022</em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>[Paper Review] AlexNet (2012)</h3><div class="text-muted small"><p> AlexNet (2012) GitHub : AlexNet Implementation 논문 소개 출처 : NIPS2012 ImageNet Classification with Deep Convolutional Neural Networks (a.k.a AlexNet) [NIPS2012] ImageNet Classification with Dee...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/day35/" class="btn btn-outline-primary" prompt="Older"><p>[BoostCamp AI Tech] Day35</p></a> <a href="/posts/day36_recsys1/" class="btn btn-outline-primary" prompt="Newer"><p>[BoostCamp AI Tech / RecSys] Day36 - RecSys with GNN</p></a></div><div id="disqus_thread" class="pt-2 pb-2"><p class="text-center text-muted small"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script type="text/javascript"> var disqus_config = function () { this.page.url = 'https://cow-coding.github.io/posts/ngcf/'; this.page.identifier = '/posts/ngcf/'; }; /* Lazy loading */ var disqus_observer = new IntersectionObserver(function (entries) { if(entries[0].isIntersecting) { (function () { var d = document, s = d.createElement('script'); s.src = 'https://cow-coding.disqus.com/embed.js'; s.setAttribute('data-timestamp', +new Date()); (d.head || d.body).appendChild(s); })(); disqus_observer.disconnect(); } }, { threshold: [0] }); disqus_observer.observe(document.querySelector('#disqus_thread')); /* Auto switch theme */ function reloadDisqus() { /* Disqus hasn't been loaded */ if (typeof DISQUS === "undefined") { return; } if (document.readyState == 'complete') { DISQUS.reset({ reload: true, config: disqus_config }); } } const modeToggle = document.querySelector(".mode-toggle"); if (typeof modeToggle !== "undefined") { /* modeToggle.addEventListener('click', reloadDisqus); // not pretty for 'color-scheme' */ window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', reloadDisqus); } </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/cow-coding">Park Kibum</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/ai-tech/">AI Tech</a> <a class="post-tag" href="/tags/boostcamp/">BoostCamp</a> <a class="post-tag" href="/tags/naver/">NAVER</a> <a class="post-tag" href="/tags/deep-learning/">Deep Learning</a> <a class="post-tag" href="/tags/mlops/">MLOps</a> <a class="post-tag" href="/tags/data-engineering/">Data Engineering</a> <a class="post-tag" href="/tags/project/">Project</a> <a class="post-tag" href="/tags/basic/">Basic</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/recommender-system/">Recommender System</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { loader: {load: ['[tex]/color']}, chtml: { scale: 1.2 }, tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ], packages: {'[+]':['color']} } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.16.1,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-163727422-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-163727422-1'); }); </script>
